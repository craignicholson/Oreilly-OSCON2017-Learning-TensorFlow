{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/oscon.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstraction layers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# contrib.learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from matplotlib import cm\n",
    "import itertools\n",
    "import numpy as np\n",
    "from tensorflow.contrib import learn\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from tensorflow.contrib import layers\n",
    "from sklearn import datasets, metrics, preprocessing\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimators\n",
    "### 1. Instantiate the Estimator class\n",
    "~~~python \n",
    "model = learn.Estimator()\n",
    "~~~\n",
    "### 2.  Fit it using training data\n",
    "~~~python \n",
    "model.fit()\n",
    "~~~\n",
    "### 3. Evaluate how good is the fit\n",
    "~~~python \n",
    "model.evaluate()\n",
    "~~~\n",
    "### 4. Predict outcomes on new data\n",
    "~~~python \n",
    "model.predict()\n",
    "~~~\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Neural Network Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "DATA_DIR = '/tmp/data'\n",
    "data = input_data.read_data_sets(DATA_DIR, one_hot=False)\n",
    "x_data, y_data = data.train.images,data.train.labels.astype(np.int32)\n",
    "x_test, y_test = data.test.images,data.test.labels.astype(np.int32)\n",
    "feature_columns = [tf.contrib.layers.real_valued_column(\"\", dimension=10)]\n",
    "\n",
    "# Or estimator using the ProximalAdagradOptimizer optimizer with\n",
    "# regularization.\n",
    "\n",
    "\n",
    "estimator = learn.DNNClassifier(\n",
    "    feature_columns=feature_columns,\n",
    "    hidden_units=[200],\n",
    "    n_classes=10,\n",
    "    optimizer=tf.train.ProximalAdagradOptimizer(\n",
    "      learning_rate=0.2,\n",
    "    ))\n",
    "\n",
    "fit = estimator.fit(x=x_data,y=y_data, steps=2000,batch_size=128)\n",
    "print('Done fitting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ev = estimator.evaluate(x=x_test,y=y_test, steps=1)[\"accuracy\"]\n",
    "print(ev)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <tr>\n",
    "    <td> <img src=\"./img/mnist-digits-small.png\"  width=\"400\"/> </td>\n",
    "    <td> <img src=\"./img/acc_vs_n_units.png\"  width=\"600\"/> </td>\n",
    "    </tr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap,aspect='auto')\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n",
    "\n",
    "y_pred = estimator.predict(x=x_test,as_iterable=False)\n",
    "class_names = ['0','1','2','3','4','5','6','7','8','9']    \n",
    "    \n",
    "    \n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure(figsize=[8,6])\n",
    "plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "                      title='Confusion matrix, without normalization')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands-on 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "boston = datasets.load_boston()\n",
    "x_data = preprocessing.StandardScaler().fit_transform(boston.data)\n",
    "y_data = boston.target\n",
    "y_data = y_data.reshape(y_data.shape + (1,))\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(x_data, y_data, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feature_columns = learn.infer_real_valued_columns_from_input(x_data)\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.1)\n",
    "\n",
    "regressor = learn.LinearRegressor(feature_columns=feature_columns,\n",
    "                                  optimizer=optimizer)\n",
    "\n",
    "##############################################\n",
    "# fit and evalute test data MSE for 1-20 steps\n",
    "##############################################\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.arange(20),MSE,lw=3,alpha=0.5)\n",
    "plt.plot(np.arange(20),MSE,'ko',alpha=0.5)\n",
    "plt.title('Boston housing test data MSE',fontsize=20)\n",
    "plt.xlabel('# steps',fontsize=20)\n",
    "plt.ylabel('MSE',fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %load solutions/solution4.py\n",
    "\n",
    "feature_columns = learn.infer_real_valued_columns_from_input(x_data)\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.1)\n",
    "\n",
    "regressor = learn.LinearRegressor(feature_columns=feature_columns,\n",
    "                                  optimizer=optimizer)\n",
    "\n",
    "MSE = []\n",
    "for i in range(20):\n",
    "    regressor.fit(x_train, y_train, steps=i, batch_size=506)\n",
    "    MSE.append(regressor.evaluate(x_test, y_test, steps=1)['loss'])\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(np.arange(20),MSE,lw=3,alpha=0.5)\n",
    "plt.plot(np.arange(20),MSE,'ko',alpha=0.5)\n",
    "plt.title('Boston housing test data MSE',fontsize=20)\n",
    "plt.xlabel('# steps',fontsize=20)\n",
    "plt.ylabel('MSE',fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a custom Estimator\n",
    "## Logistic regression:\n",
    "\n",
    "# $$Pr(y_i=1|x_i)={1\\over{1+\\exp^{wx_i+b}} }$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = 10000\n",
    "\n",
    "# generate data\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "# === Create data and simulate results =====\n",
    "x_data = np.random.randn(N,3)\n",
    "w_real = [0.3,0.5,0.1]\n",
    "b_real = -0.2\n",
    "wxb = np.matmul(w_real,x_data.T) + b_real\n",
    "\n",
    "y_data_pre_noise = sigmoid(wxb)\n",
    "y_data = np.random.binomial(1,y_data_pre_noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We construct a model function where our homemade network will reside, and also an object containing our training settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_model_fn(x_data,y_data,mode,params):\n",
    "\n",
    "    with tf.name_scope('inference') as scope:\n",
    "        w = tf.Variable([[0,0,0]],dtype=tf.float32,name='weights')\n",
    "        b = tf.Variable(0,dtype=tf.float32,name='bias')\n",
    "        y_pred = tf.matmul(w,tf.transpose(x_data)) + b\n",
    "\n",
    "    with tf.name_scope('loss') as scope:\n",
    "        y_data = tf.expand_dims(y_data,0)\n",
    "        loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=y_data,logits=y_pred) \n",
    "        loss = tf.reduce_mean(loss)\n",
    "\n",
    "    train_op = tf.contrib.layers.optimize_loss(\n",
    "        loss=loss,\n",
    "        global_step=tf.contrib.framework.get_global_step(),\n",
    "        learning_rate=params[\"learning_rate\"],\n",
    "        optimizer=\"Adagrad\")\n",
    "    \n",
    "    return y_pred, loss, train_op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input function and Feature column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encapsulating the pre-proccessing of the data as a function is required by contrib.learn, as we will see shortly. \n",
    "\n",
    "The function gets both predictors and target data in their native form (pandas data frame, numpy array, list etc.) as input, and returns a dictionary of tensors. In these dictionaries, each key is a name of a FeatureColumn \n",
    "\n",
    "This means that we also have to transform the values into a TensorFlow Tensor inside the function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature column\n",
    "\n",
    "With FeatureColumn we can maintain representation of a single feature in our data, while performing a range of transformations defined over it —a feature column can be either one of the original columns, or any new columns, depending on our transformations.All while manipulating the feature as a single semantic unit (encompassing, for example, all dummy vectors).\n",
    "\n",
    "We use the FeatureColumn function to specify the form and structure of each feature of our input data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def input_fn(x_data,y_data):\n",
    "        \n",
    "    feature_cols = {}\n",
    "    feature_cols['x_data'] = tf.constant(x_data,dtype=tf.float32)    \n",
    "    labels = tf.constant(y_data,dtype=tf.float32)\n",
    "    \n",
    "    x = tf.contrib.layers.real_valued_column('x_data')\n",
    "    \n",
    "    feature_cols = tf.contrib.layers.input_from_feature_columns(\n",
    "    columns_to_tensors=feature_cols, feature_columns=[x])\n",
    "    \n",
    "    return feature_cols, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### feature_engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def feature_engineering_fn(feature_cols, labels):\n",
    "    \"Do some prepreocessing here\"\n",
    "    return feature_cols, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_params = {\"learning_rate\": 0.5}\n",
    "est = learn.Estimator(model_fn=my_model_fn,\\\n",
    "                      feature_engineering_fn=feature_engineering_fn,\\\n",
    "                      params=model_params,\\\n",
    "                      model_dir='tmp/',\\\n",
    "                      config=tf.contrib.learn.RunConfig(save_checkpoints_secs=1))\n",
    "fit = est.fit(input_fn=lambda:input_fn(x_data,y_data),steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(est.get_variable_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w_w = est.get_variable_value('inference/weights')\n",
    "print('Estimation for weights: {}'.format(w_w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "b = est.get_variable_value('inference/bias')\n",
    "print('Estimation for bias: {}'.format(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "x_data = iris.data[:, :1]  # we only take the first two features.\n",
    "categories = np.array(['Setosa', 'Versicolour','Virginica'])\n",
    "category = categories[iris.target]\n",
    "\n",
    "y_data = iris.data[:, 1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_model_fn(feature_cols,y_data,mode,params):\n",
    "\n",
    "\n",
    "    with tf.name_scope('inference') as scope:\n",
    "        w_x = tf.Variable([[0]],dtype=tf.float32,name='w_x')\n",
    "        w_cat = tf.Variable([[0,0,0]],dtype=tf.float32,name='w_cat')\n",
    "        b = tf.Variable(0,dtype=tf.float32,name='b')\n",
    "        y_pred = tf.matmul(w_cat,tf.transpose(feature_cols[:,:3]))+\\\n",
    "                             tf.matmul(w_x,tf.transpose(feature_cols[:,3:]))\n",
    "\n",
    "    with tf.name_scope('loss') as scope:\n",
    "        y_data = tf.expand_dims(y_data,0)\n",
    "        loss = tf.reduce_mean(tf.square(y_data-y_pred))\n",
    "        loss = tf.reduce_mean(loss)\n",
    "     \n",
    "    train_op = tf.contrib.layers.optimize_loss(\n",
    "        loss=loss,\n",
    "        global_step=tf.contrib.framework.get_global_step(),\n",
    "        learning_rate=params[\"learning_rate\"],\n",
    "        optimizer=\"Adagrad\")\n",
    "    \n",
    "    return y_pred, loss, train_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input builders\n",
    "def input_fn(x_data,category,y_data):\n",
    "        \n",
    "    feature_cols = {}\n",
    "    feature_cols['x_data'] = tf.constant(x_data,dtype=tf.float32)    \n",
    "    x = tf.contrib.layers.real_valued_column('x_data')\n",
    "\n",
    "    labels = tf.constant(y_data,dtype=tf.float32)\n",
    "    \n",
    "    feature_cols['category'] = tf.SparseTensor(\n",
    "    indices=[[i, 0] for i in range(category.size)],\n",
    "    values=category, dense_shape=[category.size, 1])\n",
    "    \n",
    "    # see what's the order\n",
    "    print(list(feature_cols))\n",
    "    \n",
    "    cat=tf.contrib.layers.sparse_column_with_keys(\n",
    "    column_name='category', keys=categories)\n",
    "    \n",
    "    cat = tf.contrib.layers.one_hot_column(cat)\n",
    "        \n",
    "    feature_cols = tf.contrib.layers.input_from_feature_columns(\n",
    "    columns_to_tensors=feature_cols, feature_columns=[x,cat])\n",
    "    \n",
    "    return feature_cols, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "model_params = {\"learning_rate\": 0.5}\n",
    "est = learn.Estimator(model_fn=my_model_fn,\\\n",
    "                      params=model_params,\\\n",
    "                      config=tf.contrib.learn.RunConfig(save_checkpoints_secs=1))\n",
    "#                       model_dir='tmp/',\\\n",
    "est.fit(input_fn=lambda:input_fn(x_data,category,y_data),steps=200)\n",
    "est.evaluate(input_fn=lambda:input_fn(x_data,category,y_data),steps=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras\n",
    "Keras is one of the most popular and powerful TensorFlow extension libraries. In 2017 Keras gained official Google support, and will be moved into tf.contrib in the near future.\n",
    "\n",
    "Keras has two main types of models to choose —Sequential and functional. The sequential type is designed for simple architectures, where we just want to stack layers in a linear fashion. The functional API can support more general models with a diverse layer structure such as multi-output models or a directed acyclic graph. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Installation\n",
    "\n",
    "~~~python \n",
    "pip install keras\n",
    "~~~\n",
    "\n",
    "Or download from:\n",
    "[Git page](https://github.com/fchollet/keras)\n",
    "\n",
    "And install using:\n",
    "\n",
    "~~~python \n",
    "python setup.py install\n",
    "~~~\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense layer\n",
    "Dense\" is a fully connected layer where the first argument denotes the number of output units and the input shape is the shape of the input (in this example the weight matrix would be of size 784x64). \n",
    "\n",
    "\n",
    "\n",
    "~~~python \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation \n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=64, input_dim=784))\n",
    "model.add(Activation('softmax')~~~\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It receives three arguments: the loss function, optimizer and another metric function that is used to judge the performance of your model.\n",
    "\n",
    "~~~python \n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='sgd',\n",
    "              metrics=['accuracy'])~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set the optimizer\n",
    "\n",
    "~~~python \n",
    "optimizer=keras.optimizers.SGD(lr=0.02, momentum=0.8, nesterov=True))\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally we feed .fit() the data and set the number of epochs and batch_size. As with the previous libraries, we can now easily evaluate how it does and perform prediction with new test data.\n",
    "\n",
    "Note that a \"callbacks\" argument was added to the fit method. Callbacks are functions that are a applied during the training procedure, and we can use them to get a view on statistics and make dynamic training decisions by passing a list of them to the ,fit() method.\n",
    "\n",
    "In this example we plug in two callbacks: (1) TensorBoard, specifying its output folder, and (2) early stopping, where we specify the minimum changed to be monitored (min_delta), the number of no-improvement epochs to stop after (patience) and the direction of wanted change (mode), set here to be inferred automatically.\n",
    "\n",
    "~~~python \n",
    "from keras.callbacks import TensorBoard,EarlyStopping,ReduceLROnPlateau\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=0, mode='auto')\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=64,\n",
    "          callbacks=[TensorBoard(log_dir='/models/autoencoder',)\n",
    "          early_stop])\n",
    "\n",
    "loss_and_metrics = model.evaluate(x_test, y_test, batch_size=64)\n",
    "classes = model.predict(x_test, batch_size=64)\n",
    "~~~\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functional model\n",
    "The main difference here is that we first define our input and output, and only then instantiate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an input Tensor according to its shape\n",
    "\n",
    "~~~python \n",
    "inputs = Input(shape=(784,))\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define model\n",
    "\n",
    "~~~python \n",
    "x = Dense(64, activation='relu')(inputs)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "outputs = Dense(10, activation='softmax')(x)\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now instantiate the model, passing both inputs and outputs to \"Model\".\n",
    "\n",
    "~~~python \n",
    "model = Model(inputs=inputs, oprintutputs=outputs)\n",
    "\n",
    "from keras.callbacks import TensorBoard,EarlyStopping,ReduceLROnPlateau\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=0, mode='auto')\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=64,\n",
    "          callbacks=[TensorBoard(log_dir='/models/autoencoder',)\n",
    "          early_stop])\n",
    "\n",
    "loss_and_metrics = model.evaluate(x_test, y_test, batch_size=64)\n",
    "classes = model.predict(x_test, batch_size=64)\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras vs. Native Tensorflow\n",
    "\n",
    "### Native TensorFlow:\n",
    "\n",
    "~~~python \n",
    "initial = tf.truncated_normal([5, 5, 1, 32], stddev=0.1)\n",
    "W = tf.Variable(initial)\n",
    "initial = tf.constant(0, shape=32)\n",
    "b = tf.Variable(initial)\n",
    "img = nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "img = tf.nn.relu(img + b)\n",
    "~~~\n",
    "\n",
    "### Keras:\n",
    "\n",
    "~~~python \n",
    "init = keras.initializers.RandomNormal(mean=0.0, stddev=0.1)\n",
    "img = Conv2D(32, (5, 5),\n",
    "    activation='relu', \n",
    "    padding='same',\n",
    "    kernel_initializer=init,\n",
    "    bias_initializer='zeros'\n",
    "    )(inp_img)\n",
    "~~~\n",
    "\n",
    "### Native TensorFlow:\n",
    "\n",
    "~~~python \n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = y_conv, labels = y_))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "sess =  tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(STEPS):\n",
    "    batch = mnist.train.next_batch(MINIBATCH_SIZE)\n",
    "\n",
    "    if i % 200 == 0:\n",
    "        valid_accuracy = sess.run(accuracy, \n",
    "                                  feed_dict={x: mnist.validation.images, \n",
    "                                             y_: mnist.validation.labels,\n",
    "                                             keep_prob: 1.0})        \n",
    "\n",
    "    sess.run(train_step, feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "    \n",
    "test_accuracy = np.mean([sess.run(accuracy, feed_dict={x:x_test, y_:y_test, \n",
    "~~~\n",
    "                                              keep_prob:1.0}) for i in range(10)])    \n",
    "### Keras:\n",
    "\n",
    "~~~python \n",
    "cnn.compile(optimizer='adadelta', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "cnn.fit(x_train, y_train,\n",
    "                epochs=10,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, y_test)\n",
    "               )\n",
    "cnn.evaluate(x_test,y_test)\n",
    "~~~\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN for image classification (MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_DIR = '/tmp/data'\n",
    "data = input_data.read_data_sets(DATA_DIR, one_hot=True)\n",
    "x_train, y_train = data.train.images,data.train.labels.astype(np.int32)\n",
    "x_test, y_test = data.test.images,data.test.labels.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras import utils\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Dropout, Dense\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train = np.reshape(x_train, [-1, 28, 28, 1])\n",
    "x_test = np.reshape(x_test, [-1, 28, 28, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Dropout, Flatten\n",
    "from keras.models import Model\n",
    "\n",
    "\n",
    "inp_img = Input(shape=(28, 28, 1))  \n",
    "img = Conv2D(32, (5, 5), activation='relu', padding='same')(inp_img)\n",
    "img = MaxPooling2D((2, 2), padding='same')(img)\n",
    "img = Conv2D(64, (5, 5), activation='relu', padding='same')(img)             \n",
    "img = MaxPooling2D((2, 2), padding='same')(img)\n",
    "img = Flatten()(img)\n",
    "img = Dense(1024,activation=\"relu\")(img)\n",
    "img = Dropout(0.5)(img)\n",
    "decoded = Dense(10,activation=\"softmax\")(img)\n",
    "\n",
    "cnn = Model(inp_img, decoded)\n",
    "cnn.compile(optimizer='adadelta', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "cnn.fit(x_train, y_train,\n",
    "                epochs=10,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, y_test)\n",
    "               )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN for image classification (Cifar10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras import utils\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Dropout, Dense\n",
    "from keras.models import Model\n",
    "from keras.datasets import cifar10\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train = utils.to_categorical(y_train)\n",
    "y_test = utils.to_categorical(y_test)\n",
    "print y_train.shape\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Dropout, Flatten\n",
    "from keras.models import Model\n",
    "inp_img = Input(shape=(32, 32, 3))  \n",
    "print(\"Input layer shape: {}\".format(inp_img.get_shape()))\n",
    "\n",
    "img = Conv2D(32, (5, 5), activation='relu', padding='same')(inp_img)\n",
    "print(\"Layer 3 shape: {}\".format(img.get_shape()))\n",
    "\n",
    "img = MaxPooling2D((2, 2), padding='same')(img)\n",
    "print(\"Layer 2 shape: {}\".format(img.get_shape()))\n",
    "\n",
    "img = Conv2D(64, (5, 5), activation='relu', padding='same')(img)\n",
    "print(\"Layer 3 shape: {}\".format(img.get_shape()))\n",
    "             \n",
    "img = MaxPooling2D((2, 2), padding='same')(img)\n",
    "print(\"Layer 2 shape: {}\".format(img.get_shape()))\n",
    "\n",
    "img = Flatten()(img)\n",
    "\n",
    "img = Dense(1024,activation=\"relu\")(img)\n",
    "print(\"Layer 2 shape: {}\".format(img.get_shape()))\n",
    "\n",
    "img = Dropout(0.5)(img)\n",
    "print(\"Layer 2 shape: {}\".format(img.get_shape()))\n",
    "\n",
    "decoded = Dense(10,activation=\"softmax\")(img)\n",
    "print(\"Layer 2 shape: {}\".format(img.get_shape()))\n",
    "\n",
    "cnn = Model(inp_img, decoded)\n",
    "cnn.compile(optimizer='adadelta', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "cnn.fit(x_train, y_train,\n",
    "                epochs=10,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, y_test)\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "autoencoder.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The image input -- a 1X784 vector \n",
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "\n",
    "# The correct label\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "\n",
    "\n",
    "# With CNNs we have a spatial notion, and need the image in the correct shape!\n",
    "x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "\n",
    "# First conv layer\n",
    "conv1 = conv_layer(x_image, shape=[5, 5, 1, 32])\n",
    "conv1_pool = max_pool_2x2(conv1)\n",
    "\n",
    "# Second conv layer\n",
    "conv2 = conv_layer(conv1_pool, shape=[5, 5, 32, 64])\n",
    "conv2_pool = max_pool_2x2(conv2)\n",
    "\n",
    "# We flatten the rectangular image representation before the fully-connected part \n",
    "conv2_flat = tf.reshape(conv2_pool, [-1, 7*7*64])\n",
    "full_1 = tf.nn.relu(full_layer(conv2_flat, 1024))\n",
    "\n",
    "# Dropout\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "full1_drop = tf.nn.dropout(full_1, keep_prob=keep_prob)\n",
    "\n",
    "# Readout layer \n",
    "y_conv = full_layer(full1_drop, 10)\n",
    "\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = y_conv, labels = y_))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Autoencoders\n",
    "Output a reconstruction of the input after having its dimensionality reduced in the process\n",
    "\n",
    "Autoencoders create a bottleneck layer, called a hidden layer that has a smaller number of units than the input layer, forcing the data to be compressed before reconstructed. For the reconstruction (decoding) to be done efficiently, autoencoders extract representative features that capture some hidden abstraction.\n",
    "\n",
    "<img src=\"./img/autoencoders2.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Dropout, Dense\n",
    "from keras.models import Model\n",
    "from keras.datasets import cifar10\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we load the images using keras, and then choose only the images that correspond to label '1' (Automobile\n",
    ").\n",
    "\n",
    "Next we do a little preprocessing, first by converting our data to float32 and and normalize it to range between [0,1]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_train = x_train[np.where(y_train==1)[0],:,:,:]\n",
    "x_test = x_test[np.where(y_test==1)[0],:,:,:]\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we add some Gaussian noise, and clip values that are either smaller than 0 or larger than 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_n = x_train + 0.5 * np.random.normal(loc=0.0, scale=0.4, size=x_train.shape) \n",
    "x_test_n = x_test + 0.5 * np.random.normal(loc=0.0, scale=0.4, size=x_test.shape) \n",
    "\n",
    "x_train_n = np.clip(x_train_n, 0., 1.)\n",
    "x_test_n = np.clip(x_test_n, 0., 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n = 10\n",
    "plt.figure(figsize=(20, 2))\n",
    "for i in range(1,n):\n",
    "    ax = plt.subplot(1, n, i)\n",
    "    plt.imshow(x_test_n[i])\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We declare the input layer (every image in CIFAR is 32x32 pixels with RGB channels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Dropout\n",
    "from keras.models import Model\n",
    "inp_img = Input(shape=(32, 32, 3))  \n",
    "print(\"Input layer shape: {}\".format(inp_img.get_shape()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first layer is a 2D convolution layer, where the first argument is the number of filters (and thus the number of output images), and the second is the size of each filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img= Conv2D(32, (3, 3), activation='relu', padding='same')(inp_img)\n",
    "print(\"Layer 1 shape: {}\".format(img.get_shape()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we add more \"legos\" layers: we add a 2x2 pooling layer , another convolution layer, an up-sampling (repeating the rows and columns of the data to get back the same number of pixels in each image), and finally a convolutional output layer where we go back to 3 channels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = MaxPooling2D((2, 2), padding='same')(img)\n",
    "print(\"Layer 2 shape: {}\".format(img.get_shape()))\n",
    "\n",
    "img = Conv2D(32, (3, 3), activation='relu', padding='same')(img)\n",
    "print(\"Layer 3 shape: {}\".format(img.get_shape()))\n",
    "\n",
    "img = UpSampling2D((2, 2))(img)\n",
    "print(\"Layer 4 shape: {}\".format(img.get_shape()))\n",
    "\n",
    "decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(img)\n",
    "print(\"Layer 5 shape: {}\".format(img.get_shape()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We declare the functional model format, passing both inputs and ouputs. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "autoencoder = Model(inp_img, decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compile the model, declaring the loss function and the optimizer, in this case the Adagrad optimizer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "tensorboard = TensorBoard(log_dir='./models/autoencoder', histogram_freq=0,  \n",
    "          write_graph=True, write_images=True)\n",
    "\n",
    "model_saver = ModelCheckpoint(filepath='./models/autoencoder/autoencoder_model',verbose=0,period=2)\n",
    "\n",
    "\n",
    "autoencoder.fit(x_train_n, x_train,\n",
    "                epochs=1,\n",
    "                batch_size=64,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test_n, x_test),\n",
    "                callbacks=[tensorboard,model_saver])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import TensorBoard\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "tensorboard = TensorBoard(log_dir='./models/autoencoder', histogram_freq=0,  \n",
    "          write_graph=True, write_images=True)\n",
    "\n",
    "model_saver = ModelCheckpoint(filepath='./models/autoencoder/autoencoder_model',verbose=0,period=2)\n",
    "\n",
    "decoded_imgs = []\n",
    "\n",
    "for i in range(10):\n",
    "    autoencoder.fit(x_train_n, x_train,\n",
    "                    epochs=1,\n",
    "                    batch_size=64,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(x_test_n, x_test),\n",
    "                    callbacks=[tensorboard,model_saver])\n",
    "\n",
    "    decoded_imgs.append(autoencoder.predict(x_test_n))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# decoded_imgs = autoencoder.predict(x_test_n)\n",
    "n_imgs = 10\n",
    "f,axarr = plt.subplots(5,n_imgs,figsize=[20,10])\n",
    "for i in range(n_imgs):\n",
    "    ax = axarr[0,i]\n",
    "    ax.imshow(x_test_n[i])\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    for epoch in range(4):\n",
    "            ax = axarr[epoch+1,i]\n",
    "            ax.imshow(decoded_imgs[epoch][i])\n",
    "            plt.gray()\n",
    "            ax.get_xaxis().set_visible(False)\n",
    "            ax.get_yaxis().set_visible(False)\n",
    "            \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "decoded_imgs = autoencoder.predict(x_test_n)\n",
    "n_imgs = 10\n",
    "f,axarr = plt.subplots(2,n_imgs,figsize=[20,4])\n",
    "for i in range(n_imgs):\n",
    "    ax = axarr[0,i]\n",
    "    ax.imshow(x_test_n[i])\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    ax = axarr[1,i]\n",
    "    ax.imshow(decoded_imgs[i])\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers import LSTM, Dropout\n",
    "from keras.optimizers import SGD, RMSprop, Adagrad, Adadelta, Adam, Adamax, Nadam\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "rnn_size = 64 # The number of neurons in hidden layers.\n",
    "\n",
    "window_size = 20 # The number of previous notes (and rests) to use as input to the network \n",
    "#at each step (measured in 16th notes). It is helpful to think of this as \n",
    "#the fixed width of a piano roll rather than individual events.\n",
    "\n",
    "OUTPUT_SIZE = 129 # 0-127 notes + 1 for rests\n",
    "\n",
    "dropout = 0.2 # The normalized percentage (0-1) of weights to randomly turn \"off\" \n",
    "# in each layer during a training step. This is a regularization technique called which helps \n",
    "# prevent model overfitting. Recommended values are between 0.2 and 0.5, or 20% and 50%.\n",
    "\n",
    "\n",
    "learning_rate = 0.5 \n",
    "\n",
    "grad_clip = 5.0 # Clip backpropagated gradients to this value.\n",
    "\n",
    "\n",
    "kwargs = dict() \n",
    "kwargs['units'] = rnn_size\n",
    "kwargs['input_shape'] = (window_size, OUTPUT_SIZE)\n",
    "\n",
    "kwargs['return_sequences'] = True\n",
    "model.add(LSTM(**kwargs))\n",
    "\n",
    "model.add(LSTM(**kwargs))\n",
    "model.add(Dropout(dropout))\n",
    "kwargs['return_sequences'] = True\n",
    "\n",
    "    \n",
    "model.add(LSTM(**kwargs))\n",
    "model.add(Dropout(dropout))\n",
    "kwargs['return_sequences'] = False\n",
    "\n",
    "model.add(Dense(OUTPUT_SIZE))\n",
    "model.add(Activation('softmax'))    \n",
    "\n",
    "kwargs = { 'clipvalue': grad_clip }\n",
    "\n",
    "kwargs['lr'] = learning_rate\n",
    "\n",
    "optimizer = Adam(**kwargs)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "\n",
    "# load pitch sequences in one-hot encoding\n",
    "\n",
    "model.fit(x_train, y_train, epochs=10, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 32 # The number of samples to pass through the network before updating weights.\n",
    "\n",
    "n_jobs = 1 #The number of CPU cores to use when loading and parsing MIDI files from --data_dir. Increasing this value can dramatically speed up training. I commonly set this value to use all cores, which for my quad-core machine is 8 (Intel CPUs often have 2 virtual cores per CPU).\n",
    "\n",
    "max_files_in_ram = 25 # Files in --data_dir are loaded into RAM in small batches, processed, and then released to avoid having to load all training files into memory at once (which may be impossible when training on hundreds of files on a machine with limited memory). This value specifies the maximum number of MIDI files to keep in RAM at any one time. Using a larger number significantly speeds up training, however it also runs the risk of using too much RAM and causing your machine to start thrashing or crash. You can find a nice balance by inspecting your system monitor (Activity Monitor on MacOS and Monitor on Ubuntu) while training and adjust accourdingly.\n",
    "\n",
    "num_epochs = 10 # The number of epochs before completing training. One epoch is equal to one full pass through all midi files\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "val_split = 0.2 # use 20 percent for validation\n",
    "val_split_index = int(float(len(midi_files)) * val_split)\n",
    "\n",
    "# use generators to lazy load train/validation data, ensuring that the\n",
    "# user doesn't have to load all midi files into RAM at once\n",
    "train_generator = utils.get_data_generator(midi_files[0:val_split_index], \n",
    "                                           window_size=window_size,\n",
    "                                           batch_size=batch_size,\n",
    "                                           num_threads=n_jobs,\n",
    "                                           max_files_in_ram=max_files_in_ram)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "val_generator = utils.get_data_generator(midi_files[val_split_index:], \n",
    "                                         window_size=args.window_size,\n",
    "                                         batch_size=args.batch_size,\n",
    "                                         num_threads=args.n_jobs,\n",
    "                                         max_files_in_ram=args.max_files_in_ram)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# callbacks = get_callbacks(experiment_dir)\n",
    "\n",
    "print('fitting model...')\n",
    "# this is a somewhat magic number which is the average number of length-20 windows\n",
    "# calculated from ~5K MIDI files from the Lakh MIDI Dataset.\n",
    "magic_number = 827\n",
    "\n",
    "start_time = time.time()\n",
    "model.fit_generator(train_generator,\n",
    "                    steps_per_epoch=len(midi_files) * magic_number / args.batch_size, \n",
    "                    epochs=args.num_epochs,\n",
    "                    validation_data=val_generator, \n",
    "                    validation_steps=len(midi_files) * 0.2 * magic_number / args.batch_size,\n",
    "                    verbose=1, \n",
    "                    initial_epoch=epoch)\n",
    "\n",
    "print('Finished in {:.2f} seconds'.format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data_generator(midi_paths, \n",
    "                       window_size=20, \n",
    "                       batch_size=32,\n",
    "                       num_threads=8,\n",
    "                       max_files_in_ram=170):\n",
    "\n",
    "    if num_threads > 1:\n",
    "    \t# load midi data\n",
    "    \tpool = ThreadPool(num_threads)\n",
    "\n",
    "    load_index = 0\n",
    "\n",
    "    while True:\n",
    "        load_files = midi_paths[load_index:load_index + max_files_in_ram]\n",
    "        # print('length of load files: {}'.format(len(load_files)))\n",
    "        load_index = (load_index + max_files_in_ram) % len(midi_paths)\n",
    "\n",
    "        # print('loading large batch: {}'.format(max_files_in_ram))\n",
    "        # print('Parsing midi files...')\n",
    "        # start_time = time.time()\n",
    "        if num_threads > 1:\n",
    "       \t\tparsed = pool.map(parse_midi, load_files)\n",
    "       \telse:\n",
    "       \t\tparsed = map(parse_midi, load_files)\n",
    "        # print('Finished in {:.2f} seconds'.format(time.time() - start_time))\n",
    "        # print('parsed, now extracting data')\n",
    "        data = _windows_from_monophonic_instruments(parsed, window_size)\n",
    "        batch_index = 0\n",
    "        while batch_index + batch_size < len(data[0]):\n",
    "            # print('getting data...')\n",
    "            # print('yielding small batch: {}'.format(batch_size))\n",
    "            \n",
    "            res = (data[0][batch_index: batch_index + batch_size], \n",
    "                   data[1][batch_index: batch_index + batch_size])\n",
    "            yield res\n",
    "            batch_index = batch_index + batch_size\n",
    "        \n",
    "        # probably unneeded but why not\n",
    "        del parsed # free the mem\n",
    "        del data # free the mem\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
